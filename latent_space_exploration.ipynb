{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**WARNING**: This notebook does not work anymore as it relies on loading the models as keras models. But the old models were saved as keras models, they cannot be loaded as keras 3 models, having to be loaded with tf.saved_model.load, which does not expose layers.\n",
    "\n",
    "**DECISION**: We will not fix this notebook. If we want to conduct more experiments with the latent space exploration, we will need to save the models trained with tf>2.10 using the keras save format (on the multi-domain repository), and change this notebook to load as such accordingly.\n",
    "\n",
    "# Exploring the Latent Space of the Models\n",
    "\n",
    "Here we explore the latent space of the trained models. We will use the trained models to generate new samples and visualize the latent space of the models. We will also use the latent space to interpolate between two samples and visualize the interpolation.\n",
    "\n",
    "But first, we start by finding the most distant (in latent space) samples in the dataset (train and test) and visualize them.\n"
   ],
   "id": "666db7a10a05442f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:47:39.880065Z",
     "start_time": "2025-05-29T21:48:04.170889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gc\n",
    "import logging\n",
    "from time import time\n",
    "import tensorflow as tf\n",
    "\n",
    "import logging_utils\n",
    "\n",
    "from ModelProxy import CollaGANModelProxy, Pix2PixModelProxy, StarGANModelProxy\n",
    "\n",
    "logging_utils.configure()\n",
    "\n",
    "model_loaders = {\n",
    "    'Pix2Pix': lambda: Pix2PixModelProxy('models/pix2pix'),\n",
    "    'StarGAN': lambda: StarGANModelProxy('models/stargan'),\n",
    "    'CollaGAN': lambda: CollaGANModelProxy('models/collagan'),\n",
    "}\n"
   ],
   "id": "e5b8ace35e014f10",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-29 18:47:11.133587: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-29 18:47:11.156614: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-29 18:47:11.156655: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-29 18:47:11.171248: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-29 18:47:22.046211: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-05-29 18:47:39.255464: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-29 18:47:39.546988: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-29 18:47:39.547090: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-29 18:47:39.549266: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-29 18:47:39.549378: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-29 18:47:39.549440: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-29 18:47:39.727288: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-29 18:47:39.727391: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-29 18:47:39.727405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-05-29 18:47:39.727462: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-29 18:47:39.727491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2860 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:47:40.540215Z",
     "start_time": "2025-05-29T21:47:39.949164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataset_utils import DatasetLoader\n",
    "\n",
    "dataset_loader = DatasetLoader(\"tiny-hero\", \"test\", limit=None)\n"
   ],
   "id": "5221561d4278999a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Finds the Distance Between Two Samples in the Latent Space\n",
   "id": "14560c692fa95b70"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:47:50.029175Z",
     "start_time": "2025-05-29T21:48:39.218021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "\n",
    "def calculate_codes(model, dataset_loader, batch_size=128):\n",
    "    codes = []\n",
    "    for samples in dataset_loader.dataset.batch(batch_size):\n",
    "        z = model.encode(2, 3, samples)\n",
    "        codes.append(z)\n",
    "\n",
    "    codes = np.concatenate(codes, axis=0)\n",
    "    codes = np.reshape(codes, (dataset_loader.dataset_size, -1))\n",
    "    return codes\n",
    "\n",
    "def find_most_distant_codes(codes):\n",
    "    distances = distance.cdist(codes, codes, \"sqeuclidean\")\n",
    "    maxarg = np.unravel_index(distances.argmax(), distances.shape)\n",
    "\n",
    "    return maxarg, distances\n",
    "\n",
    "\n",
    "\n",
    "# model = model_loaders[\"StarGAN\"]()\n",
    "model = model_loaders[\"Pix2Pix\"]()\n",
    "# do a cold start of the model to have tf know which are the model inputs and outputs,\n",
    "# which is required for the StarGAN's surrogate model to properly work\n",
    "model.generate(2, 3, tf.random.uniform(shape=[1, 4, 64, 64, 4], minval=-1., maxval=1.))\n",
    "samples = []\n",
    "for dataset_name in [\n",
    "    # \"tiny-hero\",\n",
    "    \"rpg-maker-2000\",\n",
    "    \"rpg-maker-xp\",\n",
    "    \"rpg-maker-vxace\"\n",
    "]:\n",
    "    print(f\"Processing ds {dataset_name}...\")\n",
    "    dataset = DatasetLoader(dataset_name, \"train\", limit=None)\n",
    "    codes = calculate_codes(model, dataset)\n",
    "    maxarg, distances = find_most_distant_codes(codes)\n",
    "    samples = samples + [dataset.load_paired_images(maxarg[0]), dataset.load_paired_images(maxarg[1])]\n",
    "    print(\"len(samples)\", len(samples))\n",
    "    del codes\n"
   ],
   "id": "180664da1ab4d9e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-29 18:47:42 INFO     Start >> Loading Pix2Pix model front-to-right\n",
      "2025-05-29 18:47:45 INFO     Fingerprint not found. Saved model loading will continue.\n",
      "2025-05-29 18:47:45 INFO     path_and_singleprint metric could not be logged. Saved model loading will continue.\n",
      "2025-05-29 18:47:45 INFO     End   >> Loading Pix2Pix model front-to-right\n",
      "2025-05-29 18:47:45.604864: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2025-05-29 18:47:48.549169: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.67GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ds rpg-maker-2000...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MultiInputTFSMLayer' object has no attribute 'inputs'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 36\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mProcessing ds \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdataset_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     35\u001B[0m dataset \u001B[38;5;241m=\u001B[39m DatasetLoader(dataset_name, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m, limit\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m---> 36\u001B[0m codes \u001B[38;5;241m=\u001B[39m \u001B[43mcalculate_codes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     37\u001B[0m maxarg, distances \u001B[38;5;241m=\u001B[39m find_most_distant_codes(codes)\n\u001B[1;32m     38\u001B[0m samples \u001B[38;5;241m=\u001B[39m samples \u001B[38;5;241m+\u001B[39m [dataset\u001B[38;5;241m.\u001B[39mload_paired_images(maxarg[\u001B[38;5;241m0\u001B[39m]), dataset\u001B[38;5;241m.\u001B[39mload_paired_images(maxarg[\u001B[38;5;241m1\u001B[39m])]\n",
      "Cell \u001B[0;32mIn[3], line 7\u001B[0m, in \u001B[0;36mcalculate_codes\u001B[0;34m(model, dataset_loader, batch_size)\u001B[0m\n\u001B[1;32m      5\u001B[0m codes \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m dataset_loader\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39mbatch(batch_size):\n\u001B[0;32m----> 7\u001B[0m     z \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msamples\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m     codes\u001B[38;5;241m.\u001B[39mappend(z)\n\u001B[1;32m     10\u001B[0m codes \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mconcatenate(codes, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m/mnt/d/Projetos 2/dissertation-notebooks/ModelProxy.py:161\u001B[0m, in \u001B[0;36mPix2PixModelProxy.encode\u001B[0;34m(self, source_domain, target_domain, batch)\u001B[0m\n\u001B[1;32m    159\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_model(source_domain, target_domain)\n\u001B[1;32m    160\u001B[0m \u001B[38;5;66;03m# model.summary(expand_nested=True)\u001B[39;00m\n\u001B[0;32m--> 161\u001B[0m surrogate_model \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mModel(inputs\u001B[38;5;241m=\u001B[39m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minputs\u001B[49m, outputs\u001B[38;5;241m=\u001B[39mmodel\u001B[38;5;241m.\u001B[39mget_layer(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msequential_6\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39moutputs)\n\u001B[1;32m    162\u001B[0m source_image \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mgather(batch, source_domain)\n\u001B[1;32m    163\u001B[0m encoded \u001B[38;5;241m=\u001B[39m surrogate_model(source_image)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'MultiInputTFSMLayer' object has no attribute 'inputs'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "# shows an image with the four different directions in the rows and the train and test images in the columns\n",
    "rows = 4\n",
    "cols = len(samples)\n",
    "fig = plt.figure(figsize=(4*cols, 4*rows))\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        plt.subplot(rows, cols, i*cols + j + 1, facecolor='w')\n",
    "        plt.imshow(samples[j][i] * 0.5 + 0.5, interpolation=\"nearest\")\n",
    "        plt.axis(\"off\")\n",
    "fig.patch.set_alpha(0.0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig(\"output/most-distant-samples-per-dataset.png\", transparent=True)"
   ],
   "id": "d040e3f88509a54",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
